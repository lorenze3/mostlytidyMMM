Fill that control in with the location of saved hyperparameters")
}
recipe3<-recipe3|>tune::finalize_recipe(readRDS(get_control('saved_hypers_filename',wc)))
}
}
return(recipe3)
}
recipe3<-create_recipe(data_to_use=data1,
vc=variables,
mc=transform_controls,
wc=workflow_controls)
#' where R_name holds control names expected by several of this package's functions
#' and Value is the value of those controls
#' @export
#'
#' @example
#'
#' @return a recipe with roles, adstock and saturation steps defined by controls table
#'
#' @importFrom tune finalize_recipe
#' @importFrom recipes recipe
create_recipe<-function(data_to_use=data1,vc=var_controls,mc=transform_controls,
wc=workflow_controls){
#start recipe by assigning roles
#  small data is good, going to need to loop over recipe repeatedly, lots of internal copying
groupings<-as.character(groups(data_to_use))
recipe0<-recipe(head(data_to_use,n=1) )
recipe1<-recipe0 |> bulk_update_role(vars_to_append_roles=vc$varname,roles_to_be_appended=vc$role) |> bulk_add_role(vars_to_append_roles=vc$varname[!is.na(vc$role2)],roles_to_be_appended=vc$role2[!is.na(vc$role2)])
recipe2<-recipe1 |> add_steps_media(var_specific_controls=vc,media_controls=mc) |>  step_select(-has_role('postprocess'))
recipe3 <-recipe2  |># step_center(week) |>
update_role(c(sin1,sin2,sin3,sin4,sin5,cos1,cos2,cos3,cos4,cos5),new_role='time') |>
add_role(c(sin1,sin2,sin3,sin4,sin5,cos1,cos2,cos3,cos4,cos5),new_role='predictor') |>
step_novel(all_of(!!groupings)) |>
step_mutate_at(all_of(!!groupings),fn=list(id=as.integer))
if(get_control('tune_this_time',wc)=='FALSE'){
if(check_if_needs_tune(recipe3)){
if(get_control('saved_hypers_filename') =='' |
is.na(get_control('saved_hypers_filename') ) ){
stop("workflow controls calling for skipping tuning but the saved_hypers_filename control is empty!
Fill that control in with the location of saved hyperparameters")
}
recipe3<-recipe3|>tune::finalize_recipe(readRDS(get_control('saved_hypers_filename',wc)))
}
}
return(recipe3)
}
recipe3<-create_recipe(data_to_use=data1,
vc=variables,
mc=transform_controls,
wc=workflow_controls)
recipe3<-create_recipe(data_to_use=data1,
vc=variables,
mc=role_controls,
wc=workflow_controls)
recipe3
check_if_needs_tune(recipe3)
# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_full.Rmd", vignette_name = "walkthrough")
# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_full.Rmd", vignette_name = "walkthrough")
# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_full.Rmd", vignette_name = "walkthrough")
pkgdown::build_site()
fft_formulae0<-make_list_of_fft_formulae(workflow_controls,recipe3)
#split the output into two lists, one for formula and one for workflow config tables:
#list must have names for workflowsets
formulae<-fft_formulae0[[1]]
names(formulae)<-as.character(1:length(formulae))
configs_fft_options<-fft_formulae0[[2]]
length(formulae)
formulae[[2]]
formulae[[1]]
time_id_var = variables |>filter(role=='time_id')|>select(varname)|>unlist()
time_id_var
data_splits<-sliding_index(data1 %>% arrange(!!time_id_Var),!!time_id_var,lookback=52,step=52)
??sliding_index
data_splits<-rsample::sliding_index(data1 %>% arrange(!!time_id_Var),!!time_id_var,lookback=52,step=52)
data_splits<-rsample::sliding_index(data1 %>% arrange(!!time_id_var),!!time_id_var,lookback=52,step=52)
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
tune_all_these<-as_workflow_set(!!!list_of_flows)
time_id_var = variables |>filter(role=='time_id')|>select(varname)|>unlist()
data_splits<-rsample::sliding_index(data1 %>% arrange(!!time_id_var),!!time_id_var,lookback=52,step=52)
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=25,resamples=vfold_cv(data1,v=2,strata=combo_id))
suppressMessages(suppressWarnings(library(workflowsets)))
fft_formulae0<-make_list_of_fft_formulae(workflow_controls,recipe3)
#split the output into two lists, one for formula and one for workflow config tables:
#list must have names for workflowsets
formulae<-fft_formulae0[[1]]
names(formulae)<-as.character(1:length(formulae))
configs_fft_options<-fft_formulae0[[2]]
length(formulae)
formulae[[2]]
formulae[[1]]
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
tune_all_these<-as_workflow_set(!!!list_of_flows)
time_id_var = variables |>filter(role=='time_id')|>select(varname)|>unlist()
data_splits<-rsample::sliding_index(data1 %>% arrange(!!time_id_var),!!time_id_var,lookback=52,step=52)
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=25,resamples=vfold_cv(data1,v=2,strata=combo_id))
data1 %>% arrange(!!time_id_var)
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(!!time_id_var),!!time_id_var,lookback=52,step=52)
data1 |>ungroup()|> arrange(!!time_id_var)
data1 |>ungroup()|> arrange(!!time_id_var)
data1 |>ungroup()|> arrange(across(all_of(!!time_id_var)))
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=52,step=52)
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
tune_all_these<-as_workflow_set(!!!list_of_flows)
time_id_var = variables |>filter(role=='time_id')|>select(varname)|>unlist()
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=52,step=52)
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=5,resamples=vfold_cv(data1,v=2,strata=combo_id))
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
tune_all_these<-as_workflow_set(list_of_flows)
time_id_var = variables |>filter(role=='time_id')|>select(varname)|>unlist()
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=52,step=52)
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=5,resamples=vfold_cv(data1,v=2,strata=combo_id))
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
suppressMessages(suppressWarnings(library(tidymodels)))
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
tune_all_these<-as_workflow_set(list_of_flows)
tune_all_these<-as_workflow_set(!!!list_of_flows)
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
tune_all_these<-as_workflow_set(!!!list_of_flows)
time_id_var = variables |>filter(role=='time_id')|>select(varname)|>unlist()
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=52,step=52)
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=5,resamples=vfold_cv(data1,v=2,strata=combo_id))
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=5,resamples=data_splits)
data_splits
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,step=52)
data_splits$splits
data_splits$splits[[1]]
data_splits$splits[[1]]$data[data_splits$splits[[1]]$in_id ]
data_splits$splits[[1]]$data[data_splits$splits[[1]]$in_id ,]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=96,step=52)
data_splits
data_splits$splits[[1]]
?sliding_index
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,assess_stop=26,step=52)
data_splits$splits[[1]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,assess_stop=26,step=1)
data_splits$splits[[1]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=26,step=1)
data_splits$splits[[1]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=104,step=1)
data_splits$splits[[1]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=52)
data_splits$splits[[1]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=52,assess_stop=52)
data_splits$splits[[1]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=1,assess_stop=52)
data_splits$splits[[1]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,lookback=52,assess_stop=52)
data_splits$splits[[1]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,)
data_splits$id
data_splits$splits[[1]]
data_splits$splits[[208]]
data_splits$splits[[206]]
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,asses_stop=13)
data_splits<-rsample::sliding_index(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,assess_stop=13)
data_splits$id
data_splits$splits[[206]]
data_splits$splits[[203]]
?initial_time_split
names(data1)
data_splits<-rsample::initial_time_split(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),strata='store',prop=.9)
data_splits
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
tune_all_these<-as_workflow_set(!!!list_of_flows)
time_id_var = variables |>filter(role=='time_id')|>select(varname)|>unlist()
data_splits<-rsample::initial_time_split(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),strata='store',prop=.9)
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=5,resamples=data_splits)
autoplot(fft_selecting_tune_results)
rlang::last_trace()
?workflow_map
data_splits<-sliding_period(data1,!!time_id_var,period='week',
lookback=100,assess_stop=4)
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=100,assess_stop=4)
data_splits$splits[[1]]
data_splits$splits
data_splits$id
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=52,assess_stop=4)
data_splits$id
data_splits$splits[[1]]
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=52,assess_stop=4,steps=12)
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=52,assess_stop=4,step=12)
data_splits$id
#note that we can't say we are doing a good job detecting seasonality with 100 week training periods . .
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=5,resamples=data_splits)
autoplot(fft_selecting_tune_results)
id_of_best<-rank_results(fft_selecting_tune,rank_metric="rmse",select_best=F) %>%
select(wflow_id) %>% slice_head(n=1) %>% unlist()
id_of_best<-rank_results(fft_selecting_tune_results,rank_metric="rmse",select_best=F) |>
select(wflow_id) %>% slice_head(n=1) |> unlist()
rlang::last_trace()
fft_selecting_tune_results
formulae[[4]]
formulae[[3]]
formulae[[1]]
formulae[[2]]
lll<-list(1,2,3)
lll[2:3]
lll[-1]
lll
#' variable roles; the outcome, predictor, group, and time_id roles are used in determining
#' the formula.
#' @return a list with names formulae and configs, formulae is a list of strings suitable
#'  to be coerced to a formula and passed to lmer.  configs is a list of tibbles with information like vc,
#'   but reset to match a single seasonality specification.  If search_seasonality is set to FALSE in
#'   the config table, the two lists have a single formula containing the specified seasonality
#'   and no random terms.  A note is printed to the console in this case.
#' @example
#' @export
#' @importFrom
make_list_of_fft_formulae<-function(vc=workflow_controls,recipe_to_use=recipe3){
#use search_randoms control value to determine if formula created here will include
#random effects not in seaonslity. If search_randoms if TRUE, we do want to ignore
#random effects specification (for later searching)
are_we_ignoring_rands = get_control('search_randoms')=="TRUE"
if(get_control("search_seasonality")=="FALSE"){
list_of_configs=list(vc)
formulae=list(create_formula(recipe_to_use,vc,ignore_rands=are_we_ignoring_rands))
cat("Nota Bene: make_list_off_formulae is called but search_seaonality is FALSE")
}else{
fft_interact_options<-get_control("interaction_fft") |> strsplit(split=',',fixed=T) |> unlist()
if(!("" %in% fft_interact_options)){fft_interact_options=c("",fft_interact_options)}
fft_count_options<-get_control("fft_terms") |> unlist() |> as.numeric()
#vc<-workflow_controls
list_of_configs<-vector('list')
idx=0
for (this_fterms in 0:fft_count_options){
for (iterm in 1:length(fft_interact_options)){
idx=idx+1
this_iterm=fft_interact_options[iterm]
this_vc=vc |> mutate(Value=ifelse(R_name=='interaction_fft',this_iterm,Value),
Value=ifelse(R_name=='fft_terms',this_fterms,Value),
Value=ifelse(R_name=='search_seasonality',"FALSE",Value))
list_of_configs[[idx]]=this_vc
}
}
}
formulae<-lapply(list_of_configs,function(x) create_formula(recipe_to_use,x,ignore_rands = are_we_ignoring_rands))
return(list(formulae=formulae[-1],configs=list_of_configs[-1]))
}
fft_formulae0<-make_list_of_fft_formulae(workflow_controls,recipe3)
#split the output into two lists, one for formula and one for workflow config tables:
#list must have names for workflowsets
formulae<-fft_formulae0[[1]]
names(formulae)<-as.character(1:length(formulae))
configs_fft_options<-fft_formulae0[[2]]
length(formulae)
formulae[[1]]
formulae[[4]]
fft_formulae0<-make_list_of_fft_formulae(workflow_controls,recipe3)
#split the output into two lists, one for formula and one for workflow config tables:
#list must have names for workflowsets
formulae<-fft_formulae0[[1]]
names(formulae)<-as.character(1:length(formulae))
configs_fft_options<-fft_formulae0[[2]]
length(formulae)
formulae[[1]]
formulae[[3]]
fft_formulae0<-make_list_of_fft_formulae(workflow_controls,recipe3)
#split the output into two lists, one for formula and one for workflow config tables:
#list must have names for workflowsets
formulae<-fft_formulae0[[1]]
names(formulae)<-as.character(1:length(formulae))
configs_fft_options<-fft_formulae0[[2]]
length(formulae)
formulae[[1]]
formulae[[2]]
formulae[[3]]
list_of_flows<-lapply(formulae,assemble_workflow,recipe3)
tune_all_these<-as_workflow_set(!!!list_of_flows[1:2])
time_id_var = variables |>filter(role=='time_id')|>select(varname)|>unlist()
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=52,assess_stop=4,step=12)
#note that we can't say we are doing a good job detecting seasonality with 100 week training periods . .
fft_selecting_tune_results<-workflow_map(tune_all_these,grid=5,resamples=data_splits)
autoplot(fft_selecting_tune_results,'rmse')
autoplot(fft_selecting_tune_results,metric='rmse')
id_of_best<-rank_results(fft_selecting_tune_results,rank_metric="rmse",select_best=F) |>
select(wflow_id) %>% slice_head(n=1) |> unlist()
id_of_best<-rank_results(fft_selecting_tune_results,rank_metric="rmse",select_best=F) |>
select(wflow_id) %>% slice_head(n=1) |> unlist()
if(check_if_needs_tune(recipe3)){
hyper_parms<-select_best(
extract_workflow_set_result(fft_selecting_tune,id=id_of_best),metric='rmse')
hyper_parms_finalized<-recipe3 %>% finalize_recipe(hyper_parms)
}else{
hyper_parms_finalized<-recipe3
}
best_seas_vc<-configs_fft_options[[as.numeric(id_of_best)]]
best_seas_formula<-formulae[[as.numeric(id_of_best)]]
id_of_best<-rank_results(fft_selecting_tune_results,rank_metric="rmse",select_best=F) |>
select(wflow_id) %>% slice_head(n=1) |> unlist()
if(check_if_needs_tune(recipe3)){
hyper_parms<-select_best(
extract_workflow_set_result(fft_selecting_tune_results,id=id_of_best),metric='rmse')
hyper_parms_finalized<-recipe3 %>% finalize_recipe(hyper_parms)
}else{
hyper_parms_finalized<-recipe3
}
best_seas_vc<-configs_fft_options[[as.numeric(id_of_best)]]
best_seas_formula<-formulae[[as.numeric(id_of_best)]]
list_of_formulae_rands<-make_list_of_rands_formula()
list_of_formulae_rands<-make_list_of_rands_formula(
seasonality_formula = best_seas_formula,
vc = best_seas_vc
)
#' @param vc defaults to best_seas vc; a tibble with a single seasonality specification typically determined
#' by the seasonality_search process
#' @param seasonality_formula defaults to best_seas_formula; a string containing the formula for
#' all fixed effects in the model plus the seasonaity terms (which may include random slopes).
#' Typically will be produced by tuning a workflowset to identify the best seasonality specification.
#' @export
#' @return a list of strings suitable to be coerced to formula for lmer
#' and the specifications for random effects.  In the case where the control
#' search_randoms = 'FALSE' , the string in seasonality_formula is returned in a list of 1
#'
make_list_of_rands_formula<-function(seasonality_formula=best_seas_formula,
vc=best_seas_vc){
if(get_control("search_randoms",vc)=="FALSE"){
#in this case we expect that the seasonality_formula will already contain
# any random effects specified (unless some process has problematically tampered
#with the search_randoms control)
random_terms=gsub(',','+',paste(get_control("list_rand_ints",vc),
get_control('list_rand_slopes',vc),sep=','),fixed=T)
list_of_formulae_rands<-list(seasonality_formula)
cat("Nota Bene: make_list_of_rands_formula has been called
when search_randoms is FALSE\n Output is a single formula string matchting seasonality_formula.")
}
else{
list_of_formulae_rands<-vector('list')
#get all possible terms
terms_to_add<-paste(get_control("list_rand_ints",vc),
get_control('list_rand_slopes',vc),sep=',') %>% strsplit(split=',') %>% unlist()
#create all_combinations using collapsed combn output
pastey<-function(x){paste(unlist(x),collapse=" + ")}
all_combinations<-unlist(lapply(1:length(terms_to_add),function(x) combn(terms_to_add,x,FUN=pastey,simplify = F)))
for(i in 1:length(all_combinations)){
list_of_formulae_rands[[i]]<-paste0(seasonality_formula,'+',all_combinations[[i]])
}
list_of_formulae_rands<-append(list_of_formulae_rands,seasonality_formula)
}
return(list_of_formulae_rands)
}
list_of_formulae_rands<-make_list_of_rands_formula(
seasonality_formula = best_seas_formula,
vc = best_seas_vc
)
list_of_formulae_rands
list_of_flows2<-lapply(list_of_formulae_rands,assemble_workflow,hyper_parms_finalized)
tune_all_these2<-as_workflow_set(!!!list_of_flows2)
list_of_flows2<-lapply(list_of_formulae_rands,assemble_workflow,hyper_parms_finalized)
names(list_of_flows2)<-as.character(1:length(list_of_formulae_rands))
tune_all_these2<-as_workflow_set(!!!list_of_flows2)
rands_selecting_tune<-workflow_map(tune_all_these2,grid=1,resamples=data_splits)
rank_results(rands_selecting_tune)
(list_of_formulae_rands<-make_list_of_rands_formula(
seasonality_formula = best_seas_formula,
vc = best_seas_vc
) )
rands_selecting_tune
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=100,assess_stop=4,step=12)
data_splits
data_splits$id
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=60,assess_stop=4,step=12)
data_splits$id
data_splits$splits[[1]]
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=70,assess_stop=4,step=12)
data_splits$splits[[1]]
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=90,assess_stop=4,step=12)
data_splits$splits[[1]]
)
rands_selecting_tune<-workflow_map(tune_all_these2,grid=1,resamples=data_splits)
rank_results(rands_selecting_tune)
list_of_flows[[1]]
list_of_formulae_rands
assemble_workflow()
assemble_workflow
ww<-assemble_workflow(list_of_formulae_rands[[1]],recipe3)
ww<-assemble_workflow(list_of_formulae_rands[[1]],hyper_parms_finalized)
ww
list_of_flows2<-lapply(list_of_formulae_rands,assemble_workflow,hyper_parms_finalized)
list_of_flows2[[1]]
tune_all_these2<-as_workflow_set(!!!list_of_flows2)
names(list_of_flows2)<-as.character(1:length(list_of_formulae_rands))
tune_all_these2<-as_workflow_set(!!!list_of_flows2)
rands_selecting_tune<-workflow_map(tune_all_these2,grid=1,resamples=data_splits)
rands_selecting_tune
rands_selecting_tune[1,]
rands_selecting_tune[1,'result']
unlist(rands_selecting_tune[1,'result'])
suppressMessages(suppressWarnings(library(multilevelmod)))
(list_of_formulae_rands<-make_list_of_rands_formula(
seasonality_formula = best_seas_formula,
vc = best_seas_vc
) )
list_of_flows2<-lapply(list_of_formulae_rands,assemble_workflow,hyper_parms_finalized)
names(list_of_flows2)<-as.character(1:length(list_of_formulae_rands))
tune_all_these2<-as_workflow_set(!!!list_of_flows2)
data_splits<-sliding_period(data1 |>ungroup()|> arrange(across(all_of(!!time_id_var))),!!time_id_var,period='week',
lookback=90,assess_stop=4,step=12)
rands_selecting_tune<-workflow_map(tune_all_these2,grid=1,resamples=data_splits)
rank_results(rands_selecting_tune)
id_of_best_rand<-rank_results(rands_selecting_tune,rank_metric="rmse",select_best=T) %>%
select(wflow_id) %>% slice_head(n=1) %>% unlist()
best_formula<-list_of_formulae_rands[[as.numeric(id_of_best_rand)]][1]
hyper_parms
best_formula
?make_bound_statements
boundaries<-make_bound_statements(variable_controls=variables)
if(check_if_needs_tune(recipe3)){
hyper_parms<-select_best(
extract_workflow_set_result(fft_selecting_tune_results,id=id_of_best),metric='rmse')
hyper_parms_finalized_recipe<-recipe3 %>% finalize_recipe(hyper_parms)
}else{
hyper_parms_finalized_recipe<-recipe3
}
data_to_model<-bake(hyper_parms_finalized_recipe)
data_to_model<-bake(hyper_parms_finalized_recipe,data1)
data_to_model<-bake(hyper_parms_finalized_recipe|>prep(),data1)
boundaries<-make_bound_statements(variable_controls=variables)
formula_list_for_final<-create_ulam_list(prior_controls=variables, model_formula=best_formula)
data_to_model<-bake(hyper_parms_finalized_recipe|>prep(),data1)
final_fit_model<-ulam(formula_list_for_final,
constraints = boundaries,
chains=1,iter=100,
data=data_to_model,
sample = T,
#pars=c('b_week','a0','store_int',paste0('b_',final_predictors),'big_sigma','int_sigma'),
cmdstan = T,
file='ulam_fit_test_rs',
cores=4,
declare_all_data=F,
messages=F
)
boundaries<-make_bound_statements(variable_controls=variables)
formula_list_for_final<-create_ulam_list(prior_controls=variables, model_formula=best_formula)
data_to_model<-bake(hyper_parms_finalized_recipe|>prep(),data1)
final_fit_model<-rethinking::ulam(formula_list_for_final,
constraints = boundaries,
chains=1,iter=100,
data=data_to_model,
sample = T,
#pars=c('b_week','a0','store_int',paste0('b_',final_predictors),'big_sigma','int_sigma'),
cmdstan = T,
file='ulam_fit_test_rs',
cores=4,
declare_all_data=F,
messages=F
)
data_to_model$pred<-predict(final_fit_model,data_to_model)[,1]
data_to_model$pred<-predict.ulam(final_fit_model,data_to_model)[,1]
link(final_fit_model,data_to_model)
suppressMessages(suppressWarnings(library(rethinking)))
data_to_model$pred<-predict.ulam(final_fit_model,data_to_model)[,1]
this_rsq<-rsq(data_to_model|>ungroup(),truth=sales,estimate=pred)['.estimate'] %>% unlist()
this_mape<-mape(data_to_model|>ungroup(),truth=sales,estimate=pred)['.estimate'] %>% unlist()
ggplot(data_to_model ,aes(x=sales,y=pred,color=store_id))+
geom_point()+ geom_abline(slope=1,intercept=0)+ggthemes::theme_tufte()+
ggtitle("Predicted vs Actual",subtitle=paste0('Rsq is ',round(this_rsq,2)))
model_preds_long<-data_to_model %>% pivot_longer(c(pred,sales))
ggplot(model_preds_long,aes(x=week,y=value,color=name))+geom_line()+
ggtitle("Sales and Predicted Sales by Week",subtitle=paste('MAPE is',round(this_mape)))
decomps<-get_decomps_irregardless(data_to_model %>% ungroup(),recipe_to_use=hyper_parms_finalized_recipe,
model_obj=final_fit_model,
)
decomps_natl<-decomps %>% select(week,all_of(!!get_predictors_vector(hyper_parms_finalized_recipe))) %>% group_by(week) %>% summarise(across(where(is.numeric),sum))
decomps_natl<-decomps_natl %>% pivot_longer(cols=c(-week))
ggplot(data=decomps_natl,aes(x=week,y=value,fill=name)) + geom_area()+ggthemes::theme_tufte()+
ggtitle("Decomposition By Week")+
theme(legend.position = 'bottom')
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_dev-hyperparameterand-formula-search.Rmd", vignette_name = "Hyperparameter and Formula Search")
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_dev-hyperparameterand-formula-search.Rmd", vignette_name = "Hyperparameter and Formula Search")
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_dev-hyperparameterand-formula-search.Rmd", vignette_name = "Hyperparameter and Formula Search")
# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_full.Rmd", vignette_name = "walkthrough")
# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_full.Rmd", vignette_name = "walkthrough")
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_dev-hyperparameterand-formula-search.Rmd", vignette_name = "Hyperparameter and Formula Search")
pkgdown::build_site()
pkgdown::build_site()
# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_full.Rmd", vignette_name = "Demonstration of Parts of the Package")
# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_full.Rmd", vignette_name = "Demonstration of Parts of the Package")
# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_full.Rmd", vignette_name = "Demonstration of Parts of the Package")
